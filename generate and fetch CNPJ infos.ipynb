{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grequests\n",
    "from random import randint, sample\n",
    "from lxml.html import fromstring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm for generating random CNPJs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_digit(mult_array, digits_array):\n",
    "    sum_digits = sum(map(lambda x,y: x*y, mult_array, digits_array))\n",
    "    dig = sum_digits % 11\n",
    "    \n",
    "    if dig < 2:\n",
    "        dig = 0\n",
    "    else:\n",
    "        dig = 11 - dig\n",
    "\n",
    "    return dig\n",
    "\n",
    "\n",
    "def generate_cnpj():\n",
    "    cnpj_12d = str(randint(1000,1e8)).zfill(8) + '0001'\n",
    "    cnpj_int_l = [int(d) for d in list(cnpj_12d)]\n",
    "\n",
    "    first_dig = validate_digit([5,4,3,2,9,8,7,6,5,4,3,2], cnpj_int_l)\n",
    "    sec_dig = validate_digit([6,5,4,3,2,9,8,7,6,5,4,3,2], cnpj_int_l + [first_dig] )\n",
    "    return cnpj_12d + str(first_dig) + str(sec_dig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write each random CNPJ to a text file. These file will be used to fetch data from the receitaWS API\n",
    "def write_to_txt(n, list_cnpjs):\n",
    "    with open('list_cnpjs.txt', 'w') as f:\n",
    "        for cnpj in list_cnpjs:\n",
    "            f.write(f'{cnpj}\\n')\n",
    "\n",
    "\n",
    "set_cnpjs = set([generate_cnpj() for i in range(10000)])\n",
    "list_cnpjs = list(set_cnpjs)\n",
    "write_to_txt(10000, list_cnpjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt():\n",
    "    with open('list_cnpjs.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        return [x.strip() for x in lines]\n",
    "    \n",
    "list_cnpjs = read_txt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free Proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from time import time, sleep\n",
    "from pymongo import MongoClient\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_proxies():\n",
    "    response = requests.get('https://free-proxy-list.net/')\n",
    "    parser = fromstring(response.text)\n",
    "    proxies = set()\n",
    "    for i in parser.xpath('//tbody/tr')[:300]: # this site provides up to 300 free proxies\n",
    "        # We do not want transparent proxies, since they do not work to bypass APIs\n",
    "        if i.xpath('.//td[5][not(contains(text(),\"transparent\"))]'):\n",
    "            # IP + Port\n",
    "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "            proxies.add(proxy)\n",
    "    return proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_proxies = list(fetch_proxies())\n",
    "len(list_proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exception_handler(request, exception):\n",
    "    print(\"Request failed\", exception)\n",
    "\n",
    "def generate_requests(cnpjs, proxies):\n",
    "    ## Create the list for parallel connections through free proxies\n",
    "#     return [grequests.get(f'https://www.receitaws.com.br/v1/cnpj/{cnpj}', \n",
    "    return [grequests.get(f'https://www.cnpja.com.br/search-companies?taxId={cnpj}',\n",
    "                          proxies = {\n",
    "                            \"http\": f'http://{proxy}', \n",
    "                            \"https\": f'http://{proxy}' \n",
    "                          },\n",
    "                          timeout=10) \n",
    "            for cnpj, proxy in zip(cnpjs, proxies)]\n",
    "\n",
    "\n",
    "def generate_requests_noproxy(cnpjs):\n",
    "    return [grequests.get(f'https://www.cnpja.com.br/search-companies?taxId={cnpj}',\n",
    "                      timeout=10) \n",
    "        for cnpj, proxy in zip(cnpjs, proxies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_proxies(st, step, list_proxies):\n",
    "    \n",
    "    end = (st + step) % len(list_proxies)\n",
    "\n",
    "    if st > end:\n",
    "        return list_proxies[st:] + list_proxies[0:end] \n",
    "    else:\n",
    "        return list_proxies[st:end]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_json_hd(r, cnpj):\n",
    "    \n",
    "    parser = fromstring(r.text)\n",
    "    el = parser.xpath(\"//div[contains(@id, 'comp-k6fvlmw3')]//br\")\n",
    "    \n",
    "    if not el:\n",
    "        el_missing = parser.xpath(\"//div[contains(@id, 'comp-k6fvknae')]/p/span/span/span/br\")\n",
    "        if not el_missing:\n",
    "            print(f'\\nNo HTML Element found for {cnpj}')\n",
    "            return\n",
    "        else:\n",
    "            el = el_missing\n",
    "    \n",
    "    with open(f'./jsons/{cnpj}.json', 'w') as f:\n",
    "        f.write(\"{\\n\")\n",
    "        for i in range(len(el)+1):\n",
    "            s = el[0].xpath(\"./following::text()\")[i]\n",
    "\n",
    "            # Skip the lines regarding the email, which are protected against scripts(without js)\n",
    "            if s in ['\\u200c\\u200c \"email\": \"', '[email\\xa0protected]' , '\",']:\n",
    "                continue\n",
    "\n",
    "            s = s.replace(u'\\u200c',u'').replace('\\n', '')\n",
    "            f.write(f\"{s}\\n\")\n",
    "        f.write(\"}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(r, cnpj):\n",
    "    with open(f'./raw_data/{cnpj}.html', 'w') as f:\n",
    "        f.write(r.text)\n",
    "        \n",
    "        \n",
    "def check_response(resp, chosen_cnpjs, list_cnpjs):\n",
    "    \n",
    "    for r, cnpj in zip(resp, chosen_cnpjs):\n",
    "        if r:\n",
    "            if r.status_code == 200:\n",
    "                save_html(r, cnpj)\n",
    "                #write_json_hd(r, cnpj)\n",
    "                parse_bs4_save(r, cnpj)\n",
    "                list_cnpjs.remove(cnpj)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bs4_save(r, cnpj):\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    soup_full_data = soup.find(id='comp-k6fvlmw3')\n",
    "    soup_not_registered = soup.find(id='comp-k6fvknae')\n",
    "    \n",
    "    if ( soup_full_data == None) and (soup_not_registered == None):\n",
    "        print(f'\\nNo tags Found cnpj: {cnpj}')\n",
    "        return\n",
    "    \n",
    "    soup_target = soup_full_data\n",
    "    if soup_full_data != None:\n",
    "        soup_target = soup_full_data.find_all('br')\n",
    "    else:\n",
    "        soup_target = soup_not_registered.find_all('br')\n",
    "\n",
    "    with open(f'./jsons/{cnpj}.json', 'w') as f:\n",
    "        f.write(\"{\\n\")\n",
    "        for br in soup_target:\n",
    "            next_s = br.nextSibling\n",
    "            if not (next_s and isinstance(next_s,NavigableString)):\n",
    "                continue\n",
    "            next2_s = next_s.nextSibling\n",
    "\n",
    "            if next2_s and isinstance(next2_s,Tag) and next2_s.name == 'br':\n",
    "                text = str(next_s).strip()\n",
    "                if text:\n",
    "                    line = next_s.replace(u'\\u200c',u'')\n",
    "                    f.write(f\"{line}\\n\")\n",
    "                    \n",
    "        f.write(\"}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset of proxies and list_cnpjs\n",
    "proxies = list_proxies[:150]\n",
    "cnpjs = list_cnpjs[150:200]\n",
    "\n",
    "step = 20\n",
    "st = 0\n",
    "count = 0\n",
    "\n",
    "while len(cnpjs) >= step:\n",
    "    \n",
    "    if count % 3 == 0:\n",
    "        proxies = list(fetch_proxies())\n",
    "    \n",
    "    start_time = time()\n",
    "    chosen_cnpjs = sample(cnpjs, step)\n",
    "    \n",
    "    chosen_proxies = select_proxies(st, step, proxies)\n",
    "    st = (st + step) % len(list_proxies)\n",
    "    \n",
    "    reqs = generate_requests(chosen_cnpjs, chosen_proxies)\n",
    "    resp = grequests.map(reqs)\n",
    "    \n",
    "    check_response(resp, chosen_cnpjs, cnpjs)\n",
    "\n",
    "    count += 1\n",
    "    print(len(cnpjs), time()-start_time)\n",
    "    \n",
    "    sleep(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
